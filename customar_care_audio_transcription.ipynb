{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3wk02p5XFgL9"
      },
      "source": [
        "#### Project Overview\n",
        "\n",
        "This project demonstrates a customer care audio separation and transcription system. This tutorial uses the Whisper model from OpenAI for audio processing and Separation and Transcription. The main steps include loading the audio files, splitting the stereo audio into two channels (representing two speakers), transcribing the audio, and extracting useful information from the transcriptions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gwnH2zkZFBI2"
      },
      "source": [
        "### Installation of Required Libraries\n",
        "Lets install the pydub library for audio processing and the Whisper library for transcription."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t3ssB94bKVDT",
        "outputId": "efc6ff34-f4f8-48f1-c65e-dc0366de5641"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pydub in /usr/local/lib/python3.10/dist-packages (0.25.1)\n",
            "Collecting git+https://github.com/openai/whisper.git\n",
            "  Cloning https://github.com/openai/whisper.git to /tmp/pip-req-build-t7t813xc\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/openai/whisper.git /tmp/pip-req-build-t7t813xc\n",
            "  Resolved https://github.com/openai/whisper.git to commit ba3f3cd54b0e5b8ce1ab3de13e32122d0d5f98ab\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (0.58.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (1.25.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (2.3.0+cu121)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (4.66.4)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (10.1.0)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (0.7.0)\n",
            "Requirement already satisfied: triton<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (2.3.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from triton<3,>=2.0.0->openai-whisper==20231117) (3.15.4)\n",
            "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->openai-whisper==20231117) (0.41.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken->openai-whisper==20231117) (2024.5.15)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken->openai-whisper==20231117) (2.31.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (1.12.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (12.1.105)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->openai-whisper==20231117) (12.5.82)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (2024.6.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->openai-whisper==20231117) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->openai-whisper==20231117) (1.3.0)\n",
            "Requirement already satisfied: faster-whisper in /usr/local/lib/python3.10/dist-packages (1.0.3)\n",
            "Requirement already satisfied: av<13,>=11.0 in /usr/local/lib/python3.10/dist-packages (from faster-whisper) (12.2.0)\n",
            "Requirement already satisfied: ctranslate2<5,>=4.0 in /usr/local/lib/python3.10/dist-packages (from faster-whisper) (4.3.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.13 in /usr/local/lib/python3.10/dist-packages (from faster-whisper) (0.23.4)\n",
            "Requirement already satisfied: tokenizers<1,>=0.13 in /usr/local/lib/python3.10/dist-packages (from faster-whisper) (0.19.1)\n",
            "Requirement already satisfied: onnxruntime<2,>=1.14 in /usr/local/lib/python3.10/dist-packages (from faster-whisper) (1.18.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from ctranslate2<5,>=4.0->faster-whisper) (67.7.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from ctranslate2<5,>=4.0->faster-whisper) (1.25.2)\n",
            "Requirement already satisfied: pyyaml<7,>=5.3 in /usr/local/lib/python3.10/dist-packages (from ctranslate2<5,>=4.0->faster-whisper) (6.0.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.13->faster-whisper) (3.15.4)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.13->faster-whisper) (2023.6.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.13->faster-whisper) (24.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.13->faster-whisper) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.13->faster-whisper) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.13->faster-whisper) (4.12.2)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.10/dist-packages (from onnxruntime<2,>=1.14->faster-whisper) (15.0.1)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime<2,>=1.14->faster-whisper) (24.3.25)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from onnxruntime<2,>=1.14->faster-whisper) (3.20.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime<2,>=1.14->faster-whisper) (1.12.1)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.10/dist-packages (from coloredlogs->onnxruntime<2,>=1.14->faster-whisper) (10.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.13->faster-whisper) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.13->faster-whisper) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.13->faster-whisper) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.13->faster-whisper) (2024.6.2)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime<2,>=1.14->faster-whisper) (1.3.0)\n",
            "Looking in indexes: https://download.pytorch.org/whl/cu118\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.3.0+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.18.0+cu121)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.10/dist-packages (2.3.0+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.3.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.5.82)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.25.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (9.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install pydub\n",
        "!pip install -qq ipython==7.34.0\n",
        "!pip install git+https://github.com/openai/whisper.git\n",
        "!pip install faster-whisper\n",
        "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "icDGnRXHOli3"
      },
      "source": [
        "#### Restart the session before running below codes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HiHe_e_eNQ4f"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os._exit(00)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M_0zxWBeGCz0"
      },
      "source": [
        "### Load and Process Audio Files\n",
        "Load the audio file, split it into two channels, and save them as separate files.\n",
        "\n",
        "Here, I used the input audio file in stereo format where each channel represents a different speaker."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "nzmrFnboL6rI"
      },
      "outputs": [],
      "source": [
        "# Python3 program to demonstrate splitting a stereo audio file into mono channels using pydub\n",
        "\n",
        "# Import AudioSegment from pydub\n",
        "from pydub import AudioSegment\n",
        "import os\n",
        "\n",
        "# Define the audio file and the folder where it's located\n",
        "audio_filename = \"Sample Order Taking  Customer Support.mp3\"\n",
        "foldername = \"/content\"\n",
        "\n",
        "# Load the stereo audio file as an AudioSegment instance\n",
        "stereo_audio = AudioSegment.from_file(\n",
        "    os.path.join(foldername,audio_filename),\n",
        "    format=\"mp3\")\n",
        "\n",
        "# Split the stereo audio file into two mono audio segments\n",
        "mono_audios = stereo_audio.split_to_mono()\n",
        "\n",
        "# Export and save the left channel (index 0) of the mono audio segments\n",
        "mono_left = mono_audios[0].export(\n",
        "    audio_filename[:-4]+\"_left.wav\",\n",
        "    format=\"wav\")\n",
        "\n",
        "# Export and save the right channel (index 1) of the mono audio segments\n",
        "mono_right = mono_audios[1].export(\n",
        "    audio_filename[:-4]+\"_right.wav\",\n",
        "    format=\"wav\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_wgbrz6GGaFy"
      },
      "source": [
        "#### Transcribe Audio Using Whisper\n",
        "\n",
        "Load the Whisper model and transcribe the audio files. Extract the necessary information from the transcription results and save them into JSON files. This includes the segment ID, start and end times, transcribed text, and word-level details."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qHmGC3zZZpaH",
        "outputId": "7efc9652-d543-4b18-c5c6-492e1e59a698"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Time taken for left audio: 9.075596570968628\n",
            "Time taken for right audio: 16.160569429397583\n"
          ]
        }
      ],
      "source": [
        "from whisper import load_model\n",
        "import torch\n",
        "import time\n",
        "from faster_whisper import WhisperModel\n",
        "import json\n",
        "\n",
        "# Initialize the Whisper model with specified size and settings\n",
        "model_size = \"large-v3\"\n",
        "whisper_model = WhisperModel(model_size, device=\"cuda\", compute_type=\"float16\")\n",
        "\n",
        "start = time.time()\n",
        "\n",
        "# Define the paths for the left and right channel audio files\n",
        "audio_file_path_left = os.path.join(foldername, audio_filename[:-4]+\"_left.wav\")\n",
        "audio_file_path_right = os.path.join(foldername, audio_filename[:-4]+\"_right.wav\")\n",
        "\n",
        "# Transcribe the left channel audio file with word timestamps\n",
        "segments_left, info_left = whisper_model.transcribe(audio_file_path_left, beam_size=1, word_timestamps=True)\n",
        "# Transcribe the right channel audio file with word timestamps\n",
        "segments_right, info_right = whisper_model.transcribe(audio_file_path_right, beam_size=1, word_timestamps=True)\n",
        "\n",
        "# Initialize lists to hold raw and processed results\n",
        "raw_results = []\n",
        "processed_results = []\n",
        "\n",
        "# Process the transcription segments for the left channel\n",
        "for segment in segments_left:\n",
        "    segment_dict = segment._asdict()\n",
        "    raw_results.append(segment_dict)\n",
        "\n",
        "   # Prepare processed data with word-level details\n",
        "    processed_data = {\n",
        "        \"id\": segment_dict[\"id\"],\n",
        "        \"start\": segment_dict[\"start\"],\n",
        "        \"end\": segment_dict[\"end\"],\n",
        "        \"text\": segment_dict[\"text\"],\n",
        "        \"words\": [{\n",
        "            \"start\": word.start,\n",
        "            \"end\": word.end,\n",
        "            \"word\": word.word,\n",
        "            \"probability\": word.probability\n",
        "        } for word in segment_dict.get('words', [])]\n",
        "    }\n",
        "    processed_results.append(processed_data)\n",
        "\n",
        "# Write the raw and processed results to JSON files for the left channel\n",
        "try:\n",
        "    with open(\"/content/Sample Order Taking  Customer Support_left_raw_results.json\", \"w\") as raw_file, \\\n",
        "         open(\"/content/Sample Order Taking  Customer Support_left_extracted.json\", \"w\") as extracted_file:\n",
        "        json.dump(raw_results, raw_file, indent=4)\n",
        "        json.dump(processed_results, extracted_file, indent=4)\n",
        "except IOError as e:\n",
        "    print(\"An error occurred while writing files:\", e)\n",
        "\n",
        "print(\"Time taken for left audio:\", time.time() - start)\n",
        "\n",
        "# Process the transcription segments for the right channel\n",
        "for segment in segments_right:\n",
        "    segment_dict = segment._asdict()\n",
        "    raw_results.append(segment_dict)\n",
        "\n",
        "    # Prepare processed data with word-level details\n",
        "    processed_data = {\n",
        "        \"id\": segment_dict[\"id\"],\n",
        "        \"start\": segment_dict[\"start\"],\n",
        "        \"end\": segment_dict[\"end\"],\n",
        "        \"text\": segment_dict[\"text\"],\n",
        "        \"words\": [{\n",
        "            \"start\": word.start,\n",
        "            \"end\": word.end,\n",
        "            \"word\": word.word,\n",
        "            \"probability\": word.probability\n",
        "        } for word in segment_dict.get('words', [])]\n",
        "    }\n",
        "    processed_results.append(processed_data)\n",
        "\n",
        "# Write the raw and processed results to JSON files for the right channel\n",
        "try:\n",
        "    with open(\"/content/Sample Order Taking  Customer Support_right_raw_results.json\", \"w\") as raw_file, \\\n",
        "         open(\"/content/Sample Order Taking  Customer Support_right_extracted.json\", \"w\") as extracted_file:\n",
        "        json.dump(raw_results, raw_file, indent=4)\n",
        "        json.dump(processed_results, extracted_file, indent=4)\n",
        "except IOError as e:\n",
        "    print(\"An error occurred while writing files:\", e)\n",
        "\n",
        "print(\"Time taken for right audio:\", time.time() - start)\n",
        "\n",
        "# Clear GPU VRAM to free up memory\n",
        "del whisper_model\n",
        "torch.cuda.empty_cache()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sUJu2Y51RChy"
      },
      "source": [
        "#### Aligner - Combining and Sorting Transcription Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T3MqCQqGa9ex",
        "outputId": "27f4db92-ba4e-48f9-9258-2eb8888970ff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Transcription completed and saved to final_transcriped_output.json.\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "\n",
        "# Function to load JSON data from a given file path\n",
        "def load_json(file_path):\n",
        "    with open(file_path, 'r') as file:\n",
        "        return json.load(file)\n",
        "\n",
        "# Load the extracted transcription results for the left and right channels\n",
        "left_json = load_json('/content/Sample Order Taking  Customer Support_left_extracted.json')\n",
        "right_json = load_json('/content/Sample Order Taking  Customer Support_right_extracted.json')\n",
        "\n",
        "# Combine the entries from both channels and sort them by the start time\n",
        "combined_data = left_json + right_json\n",
        "sorted_data = sorted(combined_data, key=lambda x: x['start'])\n",
        "\n",
        "# Assign speaker roles and create a final structured output\n",
        "final_output = []\n",
        "for index, entry in enumerate(sorted_data, start=1):\n",
        "    speaker = \"CET Agent\" if entry in left_json else \"Customer\"\n",
        "    final_output.append({\n",
        "        \"id\": index,\n",
        "        \"text\": entry['text'].strip(),\n",
        "        \"speaker\": speaker\n",
        "    })\n",
        "\n",
        "# Save the final transcriped output to a new JSON file\n",
        "with open('/content/final_transcriped_output.json', 'w') as file:\n",
        "    json.dump(final_output, file, indent=4)\n",
        "\n",
        "print(\"Transcription completed and saved to final_transcriped_output.json.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
